{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Pzm3j6eW7i3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "here's a step-by-step guide to implementing a text summarization code using Python and the Natural Language Toolkit (NLTK) library.** **\n",
        "\n",
        "**bold text**"
      ],
      "metadata": {
        "id": "wZAhkotnXAwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install the NLTK library\n",
        "\n",
        "!pip install nltk"
      ],
      "metadata": {
        "id": "F5VLdWSqXHzQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d60af60-d4ad-402d-8ab5-4a175a96d647"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Import the necessary libraries and download the required NLTK packages\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fj_llZWqXmNY",
        "outputId": "656e148d-4e65-49c6-8544-3626241e6058"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Load the text to be summarized\n",
        "text = \"\"\"\n",
        "The Quick Brown Fox Jumps Over The Lazy Dog. \n",
        "A red sun rises, blood has been spilled this night. \n",
        "It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "6mMH3mDvXZzc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "O81D5hkDXaxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Tokenize the text into sentences and words using NLTK's sent_tokenize() and word_tokenize() functions\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "sentences = sent_tokenize(text)\n",
        "words = [word_tokenize(sentence) for sentence in sentences]"
      ],
      "metadata": {
        "id": "HhgLBSLuXbRP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Remove stop words and punctuations from the tokenized words using NLTK's stopwords corpus\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "filtered_words = []\n",
        "for sentence in words:\n",
        "    filtered_words.append([word for word in sentence if word.lower() not in stop_words and word.isalpha()])"
      ],
      "metadata": {
        "id": "MWNzqlZkYUvn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Calculate the word frequency for each word in the filtered words using Python's Counter() function\n",
        "from collections import Counter\n",
        "word_frequencies = Counter()\n",
        "for sentence in filtered_words:\n",
        "    for word in sentence:\n",
        "        word_frequencies[word] += 1"
      ],
      "metadata": {
        "id": "1slwciFjYf3r"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 7: Calculate the sentence scores based on the word frequency and sentence length using a simple algorithm\n",
        "sentence_scores = {}\n",
        "for i, sentence in enumerate(filtered_words):\n",
        "    score = 0\n",
        "    for word in sentence:\n",
        "        score += word_frequencies[word]\n",
        "    sentence_scores[i] = score / len(sentence)"
      ],
      "metadata": {
        "id": "5eQTfMPgYrZz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Select the top N sentences with the highest scores to generate the summary\n",
        "import heapq\n",
        "summary_sentences = heapq.nlargest(2, sentence_scores, key=sentence_scores.get)\n",
        "\n",
        "summary = ''\n",
        "for i in summary_sentences:\n",
        "    summary += sentences[i].strip() + ' '\n",
        "\n",
        "print(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QS8QUVZaY1a-",
        "outputId": "5aa93994-119e-482b-d5db-5273f50bbbdc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Quick Brown Fox Jumps Over The Lazy Dog. A red sun rises, blood has been spilled this night. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In this example, we selected the top 2 sentences with the highest scores to generate the summary. You can adjust this value to get a longer or shorter summary.\n",
        "\n",
        "#To test the code, you can use the following text:\n",
        "text = \"\"\"\n",
        "Python is an interpreted, high-level, general-purpose programming language. Created by Guido van Rossum and first released in 1991, Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects. Python is dynamically typed and garbage-collected. It supports multiple programming paradigms, including structured (particularly, procedural), object-oriented, and functional programming. Python is often described as a \"batteries included\" language due to its comprehensive standard library.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "Cro7bSRXZGpy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "K01jaFT4XNGZ"
      }
    }
  ]
}